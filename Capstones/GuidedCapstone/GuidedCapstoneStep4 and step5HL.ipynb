{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf5CmXQCZyF1"
   },
   "source": [
    "# Guided Capstone Step 4. Pre-Processing and Training Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2jue2jPGJlt"
   },
   "source": [
    "**The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    " \n",
    "3.   Exploratory Data Analysis   \n",
    "\n",
    "4.   **Pre-processing and Training Data Development**  \n",
    " * Create dummy or indicator features for categorical variables\n",
    "  * Standardize the magnitude of numeric features\n",
    "  * Split into testing and training datasets\n",
    "  * Apply scaler to the testing set\n",
    "5.   Modeling \n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes â€” Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8xfkAqqZyF2"
   },
   "source": [
    "**<font color='teal'> Start by loading the necessary packages as we did in step 3 and printing out our current working directory just to confirm we are in the correct project directory. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry6WPL5eZyF3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "630T-ogRZyF8"
   },
   "source": [
    "**<font color='teal'>  Load the csv file you created in step 3, remember it should be saved inside your data subfolder and print the first five rows.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMNbk0u3ZyF9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jeremysilva/Desktop/Springboard/Guided_Capstone/data\r\n"
     ]
    }
   ],
   "source": [
    "# Navigate to folder where data is store\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'data'\n",
      "/Users/jeremysilva/Desktop/Springboard/Guided_Capstone/data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 330 entries, 0 to 329\n",
      "Data columns (total 27 columns):\n",
      "Name                 330 non-null object\n",
      "state                330 non-null object\n",
      "summit_elev          330 non-null float64\n",
      "vertical_drop        330 non-null float64\n",
      "base_elev            330 non-null float64\n",
      "trams                330 non-null float64\n",
      "fastEight            330 non-null float64\n",
      "fastSixes            330 non-null float64\n",
      "fastQuads            330 non-null float64\n",
      "quad                 330 non-null float64\n",
      "triple               330 non-null float64\n",
      "double               330 non-null float64\n",
      "surface              330 non-null float64\n",
      "total_chairs         330 non-null float64\n",
      "Runs                 330 non-null float64\n",
      "TerrainParks         330 non-null float64\n",
      "LongestRun_mi        330 non-null float64\n",
      "SkiableTerrain_ac    330 non-null float64\n",
      "Snow Making_ac       330 non-null float64\n",
      "daysOpenLastYear     330 non-null float64\n",
      "yearsOpen            330 non-null float64\n",
      "averageSnowfall      330 non-null float64\n",
      "AdultWeekday         330 non-null float64\n",
      "AdultWeekend         330 non-null float64\n",
      "projectedDaysOpen    330 non-null float64\n",
      "NightSkiing_ac       330 non-null float64\n",
      "K-Means Clusters     330 non-null int64\n",
      "dtypes: float64(24), int64(1), object(2)\n",
      "memory usage: 72.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the step3 output into a dataframe called ski_data\n",
    "ski_data= pd.read_csv('step3_output.csv', index_col=[0])\n",
    "ski_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>state</th>\n",
       "      <th>summit_elev</th>\n",
       "      <th>vertical_drop</th>\n",
       "      <th>base_elev</th>\n",
       "      <th>trams</th>\n",
       "      <th>fastEight</th>\n",
       "      <th>fastSixes</th>\n",
       "      <th>fastQuads</th>\n",
       "      <th>quad</th>\n",
       "      <th>...</th>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <th>Snow Making_ac</th>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <th>yearsOpen</th>\n",
       "      <th>averageSnowfall</th>\n",
       "      <th>AdultWeekday</th>\n",
       "      <th>AdultWeekend</th>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <th>K-Means Clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Alyeska Resort</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>3939.0</td>\n",
       "      <td>962.250</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>115.103943</td>\n",
       "      <td>60.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Eaglecrest Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>1540.000</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>115.103943</td>\n",
       "      <td>44.0</td>\n",
       "      <td>156.5</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>53.00000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hilltop Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>294.000</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>115.103943</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>57.916957</td>\n",
       "      <td>64.16681</td>\n",
       "      <td>152.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Arizona Snowbowl</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>3127.5</td>\n",
       "      <td>961.125</td>\n",
       "      <td>1561.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>57.916957</td>\n",
       "      <td>89.00000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sunrise Park Resort</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>3127.5</td>\n",
       "      <td>1800.000</td>\n",
       "      <td>1561.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name    state  summit_elev  vertical_drop  base_elev  trams  \\\n",
       "0       Alyeska Resort   Alaska       3939.0        962.250      250.0    0.0   \n",
       "1  Eaglecrest Ski Area   Alaska       2600.0       1540.000     1200.0    0.0   \n",
       "2     Hilltop Ski Area   Alaska       2090.0        294.000     1796.0    0.0   \n",
       "3     Arizona Snowbowl  Arizona       3127.5        961.125     1561.5    0.0   \n",
       "4  Sunrise Park Resort  Arizona       3127.5       1800.000     1561.5    0.0   \n",
       "\n",
       "   fastEight  fastSixes  fastQuads  quad  ...  SkiableTerrain_ac  \\\n",
       "0        0.0        0.0        0.0   0.0  ...              200.0   \n",
       "1        0.0        0.0        0.0   0.0  ...              200.0   \n",
       "2        0.0        0.0        0.0   0.0  ...               30.0   \n",
       "3        0.0        0.0        0.0   0.0  ...              200.0   \n",
       "4        0.0        0.0        0.0   0.0  ...              200.0   \n",
       "\n",
       "   Snow Making_ac  daysOpenLastYear  yearsOpen  averageSnowfall  AdultWeekday  \\\n",
       "0           113.0        115.103943       60.0            158.0     65.000000   \n",
       "1            60.0        115.103943       44.0            156.5     47.000000   \n",
       "2            30.0        115.103943       36.0             69.0     57.916957   \n",
       "3           104.0        122.000000       81.0            260.0     57.916957   \n",
       "4            80.0        115.000000       49.0            250.0     74.000000   \n",
       "\n",
       "   AdultWeekend  projectedDaysOpen  NightSkiing_ac  K-Means Clusters  \n",
       "0      85.00000              150.0            27.0                 2  \n",
       "1      53.00000               90.0             0.0                 2  \n",
       "2      64.16681              152.0            30.0                 0  \n",
       "3      89.00000              122.0             0.0                 2  \n",
       "4      78.00000              104.0            27.0                 2  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ski_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkBHf9smZyGB"
   },
   "source": [
    "## Create dummy features for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWKHm0NhAnrJ"
   },
   "source": [
    "**<font color='teal'> Create dummy variables for `state`. Add the dummies back to the dataframe and remove the original column for `state`. </font>**\n",
    "\n",
    "Hint: you can see an example of how to execute this in Aiden's article on preprocessing [here](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-pre-processing-and-training-data-development-fd2d75182967). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZqWk8ltZyGZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 330 entries, 0 to 329\n",
      "Data columns (total 61 columns):\n",
      "Name                    330 non-null object\n",
      "summit_elev             330 non-null float64\n",
      "vertical_drop           330 non-null float64\n",
      "base_elev               330 non-null float64\n",
      "trams                   330 non-null float64\n",
      "fastEight               330 non-null float64\n",
      "fastSixes               330 non-null float64\n",
      "fastQuads               330 non-null float64\n",
      "quad                    330 non-null float64\n",
      "triple                  330 non-null float64\n",
      "double                  330 non-null float64\n",
      "surface                 330 non-null float64\n",
      "total_chairs            330 non-null float64\n",
      "Runs                    330 non-null float64\n",
      "TerrainParks            330 non-null float64\n",
      "LongestRun_mi           330 non-null float64\n",
      "SkiableTerrain_ac       330 non-null float64\n",
      "Snow Making_ac          330 non-null float64\n",
      "daysOpenLastYear        330 non-null float64\n",
      "yearsOpen               330 non-null float64\n",
      "averageSnowfall         330 non-null float64\n",
      "AdultWeekday            330 non-null float64\n",
      "AdultWeekend            330 non-null float64\n",
      "projectedDaysOpen       330 non-null float64\n",
      "NightSkiing_ac          330 non-null float64\n",
      "K-Means Clusters        330 non-null int64\n",
      "state_Alaska            330 non-null uint8\n",
      "state_Arizona           330 non-null uint8\n",
      "state_California        330 non-null uint8\n",
      "state_Colorado          330 non-null uint8\n",
      "state_Connecticut       330 non-null uint8\n",
      "state_Idaho             330 non-null uint8\n",
      "state_Illinois          330 non-null uint8\n",
      "state_Indiana           330 non-null uint8\n",
      "state_Iowa              330 non-null uint8\n",
      "state_Maine             330 non-null uint8\n",
      "state_Maryland          330 non-null uint8\n",
      "state_Massachusetts     330 non-null uint8\n",
      "state_Michigan          330 non-null uint8\n",
      "state_Minnesota         330 non-null uint8\n",
      "state_Missouri          330 non-null uint8\n",
      "state_Montana           330 non-null uint8\n",
      "state_Nevada            330 non-null uint8\n",
      "state_New Hampshire     330 non-null uint8\n",
      "state_New Jersey        330 non-null uint8\n",
      "state_New Mexico        330 non-null uint8\n",
      "state_New York          330 non-null uint8\n",
      "state_North Carolina    330 non-null uint8\n",
      "state_Ohio              330 non-null uint8\n",
      "state_Oregon            330 non-null uint8\n",
      "state_Pennsylvania      330 non-null uint8\n",
      "state_Rhode Island      330 non-null uint8\n",
      "state_South Dakota      330 non-null uint8\n",
      "state_Tennessee         330 non-null uint8\n",
      "state_Utah              330 non-null uint8\n",
      "state_Vermont           330 non-null uint8\n",
      "state_Virginia          330 non-null uint8\n",
      "state_Washington        330 non-null uint8\n",
      "state_West Virginia     330 non-null uint8\n",
      "state_Wisconsin         330 non-null uint8\n",
      "state_Wyoming           330 non-null uint8\n",
      "dtypes: float64(24), int64(1), object(1), uint8(35)\n",
      "memory usage: 80.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# select object type columns but drop the name column \n",
    "ski_data_obj=ski_data.select_dtypes(include=['object']).drop(columns=['Name'])\n",
    "# Concat the two dataframes and get dummies for the categorical variables\n",
    "ski_data_dum = pd.concat([ski_data.drop(ski_data_obj, axis=1), pd.get_dummies(ski_data_obj)], axis=1)\n",
    "ski_data_dum.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnDVhE1-ZyGF"
   },
   "source": [
    "## Standardize the magnitude of numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gW3D-WlDZyGG"
   },
   "source": [
    "**<font color='teal'> Using sklearn preprocessing standardize the scale of the features of the dataframe except the name of the resort which we done't need in the dataframe for modeling, so it can be droppped here as well. Also, we want to hold out our response variable(s) so we can have their true values available for model performance review. Let's set `AdultWeekend` to the y variable as our response for scaling and modeling. Later we will go back and consider the `AdultWeekday`, `dayOpenLastYear`, and `projectedDaysOpen`. For now leave them in the development dataframe. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZL-q-KtAYI6"
   },
   "outputs": [],
   "source": [
    "# first we import the preprocessing package from the sklearn library\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X = ski_data_dum.drop(['Name','AdultWeekend'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y= ski_data_dum['AdultWeekend']\n",
    "\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled=scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAT8h4_mZyGK"
   },
   "source": [
    "## Split into training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rdS8EGeAnrW"
   },
   "source": [
    "**<font color='teal'> Using sklearn model selection import train_test_split, and create a 75/25 split with the y = `AdultWeekend`. We will start by using the adult weekend ticket price as our response variable for modeling.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSkPut0gguds"
   },
   "outputs": [],
   "source": [
    "# Import the train_test_split function from the sklearn.model_selection utility.  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y = y.ravel()\n",
    "\n",
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UayqbwkWAnra"
   },
   "source": [
    "Here we start the actual modeling work. First let's fit a multiple linear regression model to predict the `AdultWeekend` price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83fkLldXFCNd"
   },
   "source": [
    "# Guided Capstone Step 5. Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbZXsVevfr9M"
   },
   "source": [
    "This is the fifth step in the Data Science Method. In the previous steps you cleaned and prepared the datasets. Now it's time to get into the most exciting part: modeling! In this exercise, you'll build three different models and compare each model's performance. In the end, you'll choose the best model for demonstrating insights to Big Mountain management.\n",
    "\n",
    "\n",
    "\n",
    "### **The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    "3.   Exploratory Data Analysis \n",
    " \n",
    "4.   Pre-processing and Training Data Development\n",
    "\n",
    "5.   **Modeling**\n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes â€” Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D_wfsP_-Anra"
   },
   "source": [
    "## Fit Models with a Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CoI8S5SwAnrc"
   },
   "source": [
    "**<font color='teal'> Using sklearn, fit the model on your training dataset.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_GFr8sRAnrd"
   },
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW6K7uOPAnre"
   },
   "outputs": [],
   "source": [
    "#all first model set\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fHqz9-WAnrg"
   },
   "source": [
    "**<font color='teal'> Predict on the testing dataset and score the model performance with the y_test set and the y-pred values. The explained variance is a measure of the variation explained by the model. This is also known as the R-squared value. </font>**\n",
    "\n",
    "Hint: you will have to use the `predict()` method here as it's used in this [DSM article](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-modeling-56b4233cad1b) about modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIo01lFEAnrh"
   },
   "outputs": [],
   "source": [
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4YS0WE2Anrk"
   },
   "source": [
    "## Review Model Outcomes â€” Iterate over additional models as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSh9sGIYAnrk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6005062094358982"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to use the explained_variance_score() and mean_absolute_error() metrics.\n",
    "# To do so, you will need to import them from sklearn.metrics. \n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error\n",
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "evs= explained_variance_score(y_test, y_pred)\n",
    "evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihzeo8tqAnro"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.940476226748405"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae= mean_absolute_error(y_test, y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWJcOuSdAnrr"
   },
   "source": [
    "**<font color='teal'> Print the intercept value from the linear model. </font>**\n",
    "\n",
    "Hint: our linear regression model `lm` has an attribute `intercept_` for the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WzWejn6Anrt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.86583824084757"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edajrenAAnrv"
   },
   "source": [
    "**<font color='teal'> The intercept is the mean `AdultWeekend` price for all the resorts given the other characteristics. The addition or subtraction of each of the coefficient values in the regression are numeric adjustments applied to the intercept to provide a particular observation's value for the resulting `AdultWeekend` value. Also, because we took the time to scale our x values in the training data, we can compare each of the coeeficients for the features to determine the feature importances. Print the coefficient values from the linear model and sort in descending order to identify the top ten most important features.</font>** \n",
    "\n",
    "\n",
    "Hint: make sure to review the absolute value of the coefficients, because the adjustment may be positive or negative, but what we are looking for is the magnitude of impact on our response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEKc_lmZAnrw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>trams</td>\n",
       "      <td>2.224546e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fastSixes</td>\n",
       "      <td>3.978081e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>state_New York</td>\n",
       "      <td>1.943592e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>quad</td>\n",
       "      <td>1.914827e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>state_Michigan</td>\n",
       "      <td>1.834223e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fastQuads</td>\n",
       "      <td>1.789231e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>state_Colorado</td>\n",
       "      <td>1.616057e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>state_California</td>\n",
       "      <td>1.581462e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>state_Pennsylvania</td>\n",
       "      <td>1.509131e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>state_Wisconsin</td>\n",
       "      <td>1.391537e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coefficient\n",
       "trams               2.224546e+13\n",
       "fastSixes           3.978081e+12\n",
       "state_New York      1.943592e+12\n",
       "quad                1.914827e+12\n",
       "state_Michigan      1.834223e+12\n",
       "fastQuads           1.789231e+12\n",
       "state_Colorado      1.616057e+12\n",
       "state_California    1.581462e+12\n",
       "state_Pennsylvania  1.509131e+12\n",
       "state_Wisconsin     1.391537e+12"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Is it right that state dummies make up the bulk of the top 10 response variables?\n",
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "coeff= pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient'])\n",
    "# Convert the coeffiecients to absolute values\n",
    "coeff= coeff.abs()\n",
    "# Sort the values by Cofficient in dewcending order to view the response variables with largest impact \n",
    "coeff= coeff.sort_values(by='Coefficient', ascending=False)\n",
    "coeff.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpdALMoAAnry"
   },
   "source": [
    "**<font color='teal'>You should see that the top ten important features are different states. However, the state is not something the managers at the Big Mountain Resort can do anything about. Given that we care more about actionable traits associated with ticket pricing, rebuild the model without the state features and compare the results. </font>**\n",
    "\n",
    "Hint: Try to construct another model using exactly the steps we followed above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mHYA1BzAnrz"
   },
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pz1YXAdiAnr0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 330 entries, 0 to 329\n",
      "Data columns (total 26 columns):\n",
      "Name                 330 non-null object\n",
      "summit_elev          330 non-null float64\n",
      "vertical_drop        330 non-null float64\n",
      "base_elev            330 non-null float64\n",
      "trams                330 non-null float64\n",
      "fastEight            330 non-null float64\n",
      "fastSixes            330 non-null float64\n",
      "fastQuads            330 non-null float64\n",
      "quad                 330 non-null float64\n",
      "triple               330 non-null float64\n",
      "double               330 non-null float64\n",
      "surface              330 non-null float64\n",
      "total_chairs         330 non-null float64\n",
      "Runs                 330 non-null float64\n",
      "TerrainParks         330 non-null float64\n",
      "LongestRun_mi        330 non-null float64\n",
      "SkiableTerrain_ac    330 non-null float64\n",
      "Snow Making_ac       330 non-null float64\n",
      "daysOpenLastYear     330 non-null float64\n",
      "yearsOpen            330 non-null float64\n",
      "averageSnowfall      330 non-null float64\n",
      "AdultWeekday         330 non-null float64\n",
      "AdultWeekend         330 non-null float64\n",
      "projectedDaysOpen    330 non-null float64\n",
      "NightSkiing_ac       330 non-null float64\n",
      "K-Means Clusters     330 non-null int64\n",
      "dtypes: float64(24), int64(1), object(1)\n",
      "memory usage: 69.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Remove all the state dummy variables and save that to a special df for this model\n",
    "ski_data_model2= ski_data_dum.iloc[:, :26]\n",
    "# Check out the model2 df\n",
    "ski_data_model2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nM1EGf16Anr2"
   },
   "outputs": [],
   "source": [
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X2 = ski_data_model2.drop(['Name','AdultWeekend'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y2= ski_data_model2['AdultWeekend']\n",
    "\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler2 = preprocessing.StandardScaler().fit(X2)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X2_scaled=scaler2.transform(X2)\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y2 = y2.ravel()\n",
    "\n",
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_scaled, y2, test_size=0.25, random_state=1)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model2 = lm.fit(X2_train,y2_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y2_pred= model2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5880419892392106"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "# It looks like EVS decreased a biy after removing the state variables\n",
    "evs2= explained_variance_score(y2_test, y2_pred)\n",
    "evs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9738066373981225"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It looks like MAE went up slightly when state variables were removed\n",
    "mae2= mean_absolute_error(y2_test, y2_pred)\n",
    "mae2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.91364641351492"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the average AdultWeekend price when accounting for all variables \n",
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AdultWeekday</td>\n",
       "      <td>6.674839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LongestRun_mi</td>\n",
       "      <td>2.067108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_chairs</td>\n",
       "      <td>1.738282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Snow Making_ac</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>daysOpenLastYear</td>\n",
       "      <td>0.805400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>base_elev</td>\n",
       "      <td>0.763218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>averageSnowfall</td>\n",
       "      <td>0.733694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>surface</td>\n",
       "      <td>0.452399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>double</td>\n",
       "      <td>0.422685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SkiableTerrain_ac</td>\n",
       "      <td>0.359996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coefficient\n",
       "AdultWeekday          6.674839\n",
       "LongestRun_mi         2.067108\n",
       "total_chairs          1.738282\n",
       "Snow Making_ac        0.816452\n",
       "daysOpenLastYear      0.805400\n",
       "base_elev             0.763218\n",
       "averageSnowfall       0.733694\n",
       "surface               0.452399\n",
       "double                0.422685\n",
       "SkiableTerrain_ac     0.359996"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "coeff= pd.DataFrame(abs(lm.coef_), X2.columns, columns=['Coefficient'])\n",
    "# Convert the coeffiecients to absolute values\n",
    "coeff= coeff.abs()\n",
    "# Sort the values by Cofficient in dewcending order to view the response variables with largest impact \n",
    "coeff= coeff.sort_values(by='Coefficient', ascending=False)\n",
    "coeff.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWjQLr3LAnr6"
   },
   "source": [
    "**<font color='teal'> When reviewing our new model coefficients, we see `summit_elev` is now in the number two spot. This is also difficult to change from a management prespective and highly correlated with `base_elev` and `vertical_drop`.  This time, rebuild the model without the state features and without the `summit_elev` and without `base_elev`and compare the results. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I don't have summit_elev in the number 10 spot. I am assuming that has something to do with me using replacement\n",
    "### for the outliers instead of removing them entirely "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXqvcn93Anr7"
   },
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eugnDNNAnr8"
   },
   "outputs": [],
   "source": [
    "# Creating a new model without summit_elev and base_elev \n",
    "ski_data_model3= ski_data_model2.drop(columns=['summit_elev', 'base_elev'])\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X3 = ski_data_model3.drop(['Name','AdultWeekend'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y3= ski_data_model3['AdultWeekend']\n",
    "\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler3 = preprocessing.StandardScaler().fit(X3)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X3_scaled=scaler3.transform(X3)\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y3 = y3.ravel()\n",
    "\n",
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_scaled, y3, test_size=0.25, random_state=1)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model3 = lm.fit(X3_train,y3_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y3_pred= model3.predict(X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pq0pW7G9Anr_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6001980088362145"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "evs3= explained_variance_score(y3_test, y3_pred)\n",
    "evs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reXlf0HAAnsG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.91205922656483"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It looks like MAE went up slightly when state variables were removed\n",
    "mae3= mean_absolute_error(y3_test, y3_pred)\n",
    "mae3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AdultWeekday</td>\n",
       "      <td>6.618953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LongestRun_mi</td>\n",
       "      <td>2.084502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_chairs</td>\n",
       "      <td>1.746368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Snow Making_ac</td>\n",
       "      <td>0.810174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>daysOpenLastYear</td>\n",
       "      <td>0.803272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>K-Means Clusters</td>\n",
       "      <td>0.771129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>averageSnowfall</td>\n",
       "      <td>0.732763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>surface</td>\n",
       "      <td>0.503409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>double</td>\n",
       "      <td>0.423137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SkiableTerrain_ac</td>\n",
       "      <td>0.368313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coefficient\n",
       "AdultWeekday          6.618953\n",
       "LongestRun_mi         2.084502\n",
       "total_chairs          1.746368\n",
       "Snow Making_ac        0.810174\n",
       "daysOpenLastYear      0.803272\n",
       "K-Means Clusters      0.771129\n",
       "averageSnowfall       0.732763\n",
       "surface               0.503409\n",
       "double                0.423137\n",
       "SkiableTerrain_ac     0.368313"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "coeff= pd.DataFrame(abs(lm.coef_), X3.columns, columns=['Coefficient'])\n",
    "# Convert the coeffiecients to absolute values\n",
    "coeff= coeff.abs()\n",
    "# Sort the values by Cofficient in dewcending order to view the response variables with largest impact \n",
    "coeff= coeff.sort_values(by='Coefficient', ascending=False)\n",
    "coeff.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJvQMns6AnsI"
   },
   "source": [
    "## Identify the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LD7-3iLcAnsK"
   },
   "source": [
    "**<font color='teal'> Review the model performances in the table below and choose the best model for proving insights to Big Mountain management about what features are driving ski resort lift ticket prices. Type your choice in the final markdown cell â€” you will discuss this selection more in the next step of the guided casptone. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "La5S9fRPAnsK"
   },
   "source": [
    "| Model | Explained Variance| Mean Absolute Error|Features Dropped|\n",
    "| --- | --- | --- | --- |\n",
    "| Model 1. | evs |  |-|\n",
    "| Model 2. | evs2| |'state'|\n",
    "| Model 3. | evs3 | |'state','summit_elev','base_elev'|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Explained Variance</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Features Dropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Model 1</td>\n",
       "      <td>0.600506</td>\n",
       "      <td>5.940476</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Model 2</td>\n",
       "      <td>0.588042</td>\n",
       "      <td>5.973807</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Model 3</td>\n",
       "      <td>0.600198</td>\n",
       "      <td>5.912059</td>\n",
       "      <td>state, summit_elev, base_elev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Explained Variance  Mean Absolute Error  \\\n",
       "0  Model 1            0.600506             5.940476   \n",
       "1  Model 2            0.588042             5.973807   \n",
       "2  Model 3            0.600198             5.912059   \n",
       "\n",
       "                Features Dropped  \n",
       "0                           none  \n",
       "1                          state  \n",
       "2  state, summit_elev, base_elev  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= [['Model 1', evs, mae, 'none'], ['Model 2', evs2, mae2, 'state'], ['Model 3', evs3, mae3, 'state, summit_elev, base_elev']]\n",
    "models_df= pd.DataFrame(data, columns=['Model', 'Explained Variance', 'Mean Absolute Error', 'Features Dropped'])\n",
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2c-zn7TAnsL"
   },
   "source": [
    "Model Selection: Model 3 it has the 2nd best EVS and MAE but it has the most relevant columns in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgC0eMBrAnsM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RtEspslPZyGY",
    "s0DokMkAZyGc",
    "2iuitnKcZyHS",
    "iAWQxougZyHW",
    "ThMTimlBZyHZ",
    "QwZ-LkjXZyHt",
    "srtXEA3N4-Y9",
    "ChVreJupZyIA",
    "zDgSSsq1ZyID",
    "I3GYKWfi5Llg",
    "pmMvrhbI-viE",
    "ZXDPkW3UZyIX",
    "Dnc_vHQLZyId",
    "daJxuJ-dZyIg",
    "mAQ-oHiPZyIn",
    "hnGOsp3mZyIp"
   ],
   "name": "GuidedCapstoneStep5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
